{"cells":[{"cell_type":"code","source":["# https://docs.microsoft.com/en-us/azure/azure-databricks/databricks-stream-from-eventhubs\n# https://github.com/Azure/azure-event-hubs-spark/blob/master/docs/PySpark/structured-streaming-pyspark.md\n\nconnectionString = \"Endpoint=sb://ihsuprodblres058dednamespace.servicebus.windows.net/;SharedAccessKeyName=iothubowner;SharedAccessKey=1hiERMO+U01xjClcFab/Xk2nRGWYTCP6X5a2QnMEj/Y=;EntityPath=iothub-ehub-contosohub-448302-7369b6590a\"\n\nehConf = {\n  'eventhubs.connectionString' : connectionString\n}\n\ndf = spark \\\n  .readStream \\\n  .format(\"eventhubs\") \\\n  .options(**ehConf) \\\n  .load()\n  \ndata = df.selectExpr(\"CAST(body as STRING)\")\n\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import DoubleType\njsDf = data.select(get_json_object(data['body'],\"$.Id\").alias('DeviceId'),\n                               get_json_object(data['body'],\"$.X\").alias('X').cast(DoubleType()),\n                               get_json_object(data['body'],\"$.Y\").alias('Y').cast(DoubleType()),\n                               get_json_object(data['body'],\"$.Z\").alias('Z').cast(DoubleType()))\n\nfell = jsDf.filter(jsDf['Y'] == 0.5)\n\nwriteConnectionString = \"Endpoint=sb://ndccontosons.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=cbBE7Zx8/nCxcStHlF+qteYNV6DM5ohZkCBr5wYkCJY=;EntityPath=ndccontosoeh\"\nehWriteConf = {\n  'eventhubs.connectionString' : writeConnectionString\n}\n\nds = df \\\n  .select(\"body\") \\\n  .writeStream \\\n  .format(\"eventhubs\") \\\n  .options(**ehWriteConf) \\\n  .option(\"checkpointLocation\", \"///output.txt\") \\\n  .start()"],"metadata":{},"outputs":[],"execution_count":1}],"metadata":{"name":"GrandmaFell","notebookId":3413813636162716},"nbformat":4,"nbformat_minor":0}
